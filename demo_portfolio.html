<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css"
      rel="stylesheet"
    />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css"
    />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.0/font/bootstrap-icons.css"
    />
    <title>Cameron Olson | Portfolio</title>
    <style>
      /* Custom CSS */
      .link-container {
        margin-bottom: 15px;
      }
      .bi {
        margin-right: 10px;
      }
      a {
        color: #007bff;
        text-decoration: none;
      }
      a:hover {
        text-decoration: underline;
      }
      body {
        font-family: "Arial", sans-serif;
      }
      header {
        background: #343a40;
      }
      header h1,
      header h3 {
        margin: 0;
      }
      header a {
        display: block;
        margin-top: 10px;
      }
      nav {
        background: #6c757d;
      }
      nav a {
        color: white;
        padding: 10px 15px;
        display: inline-block;
      }
      section {
        padding: 60px 0;
      }
      footer {
        background: #343a40;
        color: white;
        text-align: center;
        padding: 30px 0;
      }
      .img-fluid {
        max-width: 100%;
        height: auto;
      }
      .timeline ul {
        list-style-type: none;
        padding: 0;
      }
      .timeline ul li {
        padding: 20px;
        background: #f8f9fa;
        margin-bottom: 10px;
        border-radius: 5px;
      }
      .card {
        margin-bottom: 30px;
        border: none;
        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
      }
      .card img {
        border-top-left-radius: 15px;
        border-top-right-radius: 15px;
      }
      .card h4 {
        margin-bottom: 15px;
      }
      .card ul {
        list-style-type: none;
        padding: 0;
      }
      .card ul li {
        margin-bottom: 5px;
      }
      .project-image {
        background-size: cover;
        background-position: center;
        height: 150px; /* Adjust the height as per your design requirement */
        border-top-left-radius: 15px;
        border-top-right-radius: 15px;
      }

      .card-body h3,
      .card-body h4 {
        border-bottom: 2px solid #191b19; /* Green Color for Underline */
        padding-bottom: 10px;
        margin-bottom: 10px;
      }

      .card-body ul li {
        margin-bottom: 5px;
      }

      #about-me {
        background-color: #e3e3e3; /* Dark Grey */
        color: #000000; /* White */
      }

      #about-me h2 {
        color: #000000; /* Green */
      }
    </style>

    <script
      src="https://code.jquery.com/jquery-3.6.0.min.js"
      crossorigin="anonymous"
    ></script>

    <script>
      $(document).ready(function () {
        // When the specific link with ID 'specialLink' is clicked...
        $(".my-link").click(function (e) {
          // Prevent the default behavior of the link
          e.preventDefault();

          // Get the target section ID from the href attribute of the link
          var targetSectionId = $(this).attr("href");
          $("#project1Modal").modal("hide");

          // When the specific modal is hidden...
          $("#project1Modal").one("hidden.bs.modal", function () {
            // Smoothly scroll to the target section
            $("html, body").animate(
              {
                scrollTop: $(targetSectionId).offset().top,
              },
              10
            ); // Adjust scroll speed
          });
        });
      });
      $(document).ready(function () {
        // When the specific link with ID 'specialLink' is clicked...
        $(".my-link-2").click(function (e) {
          // Prevent the default behavior of the link
          e.preventDefault();

          // Get the target section ID from the href attribute of the link
          var targetSectionId = $(this).attr("href");
          $("#project2Modal").modal("hide");

          // When the specific modal is hidden...
          $("#project2Modal").one("hidden.bs.modal", function () {
            // Smoothly scroll to the target section
            $("html, body").animate(
              {
                scrollTop: $(targetSectionId).offset().top,
              },
              10
            ); // Adjust scroll speed
          });
        });
      });
    </script>
  </head>
  <body>
    <header class="p-5 text-white text-center">
      <h1>Cameron Olson</h1>
      <h3>Audio Deep Learning</h3>
      <a
        href="https://github.com/cmsolson75"
        target="_blank"
        class="text-white"
      >
        <i class="fab fa-github"></i> GitHub
      </a>
    </header>

    <nav class="text-center">
      <a href="#biography">Biography</a>
      <a href="#projects">Projects</a>
      <a href="#music">Music</a>
      <a href="#education">Education</a>
      <a href="#contact">Contact</a>
      <a href="documents/Cameron_Olson_Resume.pdf" download="cameron_olson_resume" target="_blank">Resume</a>
    </nav>

    <section class="p-5" id="biography">
      <div class="container">
        <h2 class="text-center">Biography</h2>
        <p>
          Cameron Olson, a computer musician, coder, and recent graduate,
          seamlessly blends his passion for music and technology, particularly
          within the realm of Artificial Intelligence. With a specialization in
          Audio Deep Learning, Cameron harnesses AI to create innovative
          auditory experiences, notably through his project, "Almost Human,"
          which crafts AI-powered music that challenges and expands the
          boundaries of traditional composition and production. His commitment
          to making art more connected and accessible through technology
          resonates not only in his creations but also in his steadfast belief
          that everyone, including those with learning disabilities like him,
          deserves the right to self-expression. Although Cameron has concluded
          his academic journey at Berklee College of Music, where he delved
          deeply into electronic production and design, his expertise in Python
          and multifaceted experience in music—spanning composition, sound
          design, production, and audio delivery—continue to propel his
          professional and artistic explorations. His rich history as a jazz
          drummer, with five years of professional playing under his belt,
          underscores his versatile musicianship and informs his innovative
          approach to melding technological and musical realms.
        </p>
      </div>
    </section>

    <section class="p-5 bg-light" id="projects">
      <div class="container">
        <h2 class="text-center mb-4">Projects</h2>

        <!-- <p></p> -->
        <div class="row">
          <article class="col-md-6">
            <div class="card">
              <!-- Old img tag removed -->
              <!-- New div tag for project image -->
              <div
                class="project-image"
                style="
                  background-image: url('/Users/cameronolson/Developer/PersonalProject/PortfolioWebsite/PortfolioWebsiteDraft1/images/DALL·E 2022-11-02 18.55.04 - Creation.png');
                "
              ></div>
              <div class="card-body">
                <!-- <h4>Exploration of Audio Diffusion Synthesis</h4> -->
                <h4>Exploring Audio Diffusion Synthesis</h4>
                <p>
                  Undergraduate Thesis | Berklee College of Music | Advisor: Dr.
                  Richard Boulanger
                </p>
                <p>
                  My undergraduate thesis, 'Exploring Audio Diffusion
                  Synthesis,' offers a thorough analysis of Raw Audio Neural
                  Network Generation, exploring the adaptation and application
                  of novel AI technologies to satisfy musicians' requirements
                  and innovate in sound design. The project blends theory and
                  practice, supporting findings with a research paper and a
                  dataset of 20,000+ drum samples. I also created music to
                  showcase the practical and creative possibilities of the AI
                  models in sound design.
                </p>
                <!-- Button trigger modal -->
                <button
                  type="button"
                  class="btn btn-dark"
                  data-bs-toggle="modal"
                  data-bs-target="#project1Modal"
                >
                  Learn More
                </button>
              </div>
            </div>
          </article>
          <!-- Additional project cards... -->

          <article class="col-md-6">
            <div class="card">
              <div
                class="project-image"
                style="
                  background-image: url('/Users/cameronolson/Developer/PersonalProject/PortfolioWebsite/PortfolioWebsiteDraft1/images/DALL·E 2022-11-02 19.02.33 - album art almost human.png');
                "
              ></div>
              <div class="card-body">
                <h4>Almost Human</h4>
                <p>Artist project | AI Song Competition</p>
                <p>
                  "Almost Human," an innovative artistic endeavor initiated at
                  Berklee College of Music, delves deep into the intricate
                  interplay between Machine Learning and the Artist. This
                  collective is propelled by the conviction that the future of
                  music resides at the crossroads of cutting-edge technology and
                  human creativity. We aspire to democratize the sheer joy of
                  music creation, ensuring that this exhilarating experience is
                  open and available to everyone.
                </p>
                <!-- Optional: You might have a button or link here -->
                <!-- Button trigger modal -->
                <button
                  type="button"
                  class="btn btn-dark"
                  data-bs-toggle="modal"
                  data-bs-target="#project2Modal"
                >
                  Learn More
                </button>
              </div>
            </div>
          </article>
          
          <article class="col-md-6">
            <div class="card">
              <!-- New div tag for project image -->
              <div
                class="project-image"
                style="
                  background-image: url('/Users/cameronolson/Developer/PersonalProject/PortfolioWebsite/PortfolioWebsiteDraft1/images/DALL·E 2022-11-02 19.00.18 - Creation of water glitching clarity to another dimension purple depicted as a nebula fractal explosion.png');
                "
              ></div>
              <div class="card-body">
                <h4>Catch-A-Waveform: Google Colab Notebook</h4>
                <p>Open Source Contribution</p>
                <p>
                  "Catch-A-Waveform" is a project primarily focused on audio
                  generation and manipulation, with capabilities to generate
                  audio from a single short example. This is a full Google Colab
                  build of a modified Catch-A-Waveform repository from the
                  Dadabots' Zack Zukowski.
                </p>
                <!-- Optional: You might have a button or link here -->
                <!-- Button trigger modal -->
                <button
                  type="button"
                  class="btn btn-dark"
                  data-bs-toggle="modal"
                  data-bs-target="#project3Modal"
                >
                  Learn More
                </button>
              </div>
            </div>
          </article>
          <article class="col-md-6">
            <div class="card">
              <!-- New div tag for project image -->
              <div
                class="project-image"
                style="
                  background-image: url('/Users/cameronolson/Developer/PersonalProject/PortfolioWebsite/PortfolioWebsiteDraft1/images/DALL·E 2022-11-04 16.54.26 - Robot Screaming as an echo of a human as a portal to another dimension.png');
                "
              ></div>
              <div class="card-body">
                <h4>MNIST Deployment Project</h4>
                <p>Coding Project</p>
                <p>
                  The MNIST Hand-Drawn Digit Recognition project is a
                  Python-based application that utilizes Deep Learning to
                  recognize hand-drawn digits. The project is structured to
                  train a neural network model on the MNIST dataset and
                  subsequently provide a graphical user interface (GUI) for
                  real-time digit recognition.
                </p>
                <!-- Optional: You might have a button or link here -->
                <button
                  type="button"
                  class="btn btn-dark"
                  data-bs-toggle="modal"
                  data-bs-target="#project4Modal"
                >
                  Learn More
                </button>
              </div>
            </div>
          </article>

          <article class="col-md-6">
            <div class="card">
              <!-- New div tag for project image -->
              <div
                class="project-image"
                style="
                  background-image: url('/Users/cameronolson/Developer/PersonalProject/PortfolioWebsite/PortfolioWebsiteDraft1/images/DALL·E 2022-11-02 18.57.31 - Creation of water glitching clarity.png');
                "
              ></div>
              <div class="card-body">
                <h4>Youtube Playlist Length Calculator</h4>
                <p>Pair Programming Project</p>
                <p>
                  The YouTube Playlist Length Calculator is a Python script
                  designed to calculate the total duration of all videos within
                  a specified YouTube playlist. This can be particularly useful
                  for assessing the total watch time of course material,
                  tutorial series, or any collection of videos grouped into a
                  YouTube playlist.
                </p>
                <button
                  type="button"
                  class="btn btn-dark"
                  data-bs-toggle="modal"
                  data-bs-target="#project5Modal"
                >
                  Learn More
                </button>
                <!-- Optional: You might have a button or link here -->
              </div>
            </div>
          </article>

          <article class="col-md-6">
            <div class="card">
              <!-- New div tag for project image -->
              <div
                class="project-image"
                style="
                  background-image: url('/Users/cameronolson/Developer/PersonalProject/PortfolioWebsite/PortfolioWebsiteDraft1/images/DALL·E 2022-11-02 18.57.57 - Creation of water glitching clarity to another dimension.png');
                "
              ></div>
              <div class="card-body">
                <h4>Socket Morse Chat App</h4>
                <p>Pair Programming Project | Network Programming</p>
                <p>
                  The Socket Morse Chat App is a communication application
                  developed in Python that allows users to send and receive
                  messages in Morse code through a client-server architecture.
                  The application translates text messages into Morse code and
                  plays the corresponding audio to the users.
                </p>
                <!-- Optional: You might have a button or link here -->
                <button
                  type="button"
                  class="btn btn-dark"
                  data-bs-toggle="modal"
                  data-bs-target="#project6Modal"
                >
                  Learn More
                </button>
              </div>
            </div>
          </article>
        </div>
      </div>
    </section>

    <!-- Modal for Project 1 -->
    <div
      class="modal fade"
      id="project1Modal"
      tabindex="-1"
      aria-labelledby="project1ModalLabel"
      aria-hidden="true"
    >
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="modal-header">
            <h5 class="modal-title" id="project1ModalLabel">
              Exploration of Audio Diffusion Synthesis
            </h5>
            <button
              type="button"
              class="btn-close"
              data-bs-dismiss="modal"
              aria-label="Close"
            ></button>
          </div>
          <div class="modal-body">
            <h5>Overview</h5>
            <p>
              My undergraduate thesis, 'Exploring Audio Diffusion Synthesis,'
              offers a thorough analysis of Raw Audio Neural Network Generation,
              exploring the adaptation and application of novel AI technologies
              to satisfy musicians' requirements and innovate in sound design.
              The project blends theory and practice, supporting findings with a
              research paper and a dataset of 20,000+ drum samples. I also
              created music to showcase the practical and creative possibilities
              of the AI models in sound design.
            </p>
            <h5>Key Points</h5>
            <!-- Key Contributions & Abstract Here -->

            <ul>
              <li>
                <strong>Dataset Assembly:</strong> Compiled a robust dataset of
                20,000+ drum samples, ensuring a comprehensive basis for
                subsequent neural network training and experimental validation.
              </li>
              <li>
                <strong>AI Model Development and Application:</strong>
                Engineered and trained AI models in the domain of Audio
                Diffusion Synthesis, utilizing them to generate music and
                exemplify their pragmatic and innovative applications in sound
                design.
              </li>
              <li>
                <strong>Research Synthesis:</strong> Conducted rigorous research
                into Raw Audio Neural Network Generation, culminating in a
                scholarly research paper that encapsulates the findings and
                theoretical underpinnings of the explored technologies.
              </li>
              <li>
                <strong>Technological Exploration:</strong> Investigated and
                implemented emerging AI technologies, tailoring them to address
                specific requisites of musicians and to innovate in the field of
                sound design, with a particular focus on diffusion synthesis
                using the open-source Dance Diffusion model by Harmonai for a
                large portion of my research.
              </li>
              <li>
                <strong>Presentation of Findings:</strong> Articulated research
                findings and practical applications through a multifaceted
                presentation approach, encompassing a research paper, a showcase
                video, and a master class, targeting both academic and
                practitioner audiences at Berklee.
              </li>
            </ul>

            <h5>Abstract</h5>
            <p>
              This research dives into Audio Diffusion Synthesis, exploring the
              potential of Neural Networks in sound generation. Specifically
              focusing on the Dance Diffusion architecture, the paper navigates
              through system selection, data collection, and model training,
              demonstrating the effectiveness of DDPMs in generating
              authentic-sounding audio signals, providing valuable insights into
              the future of audio synthesis in music production.
            </p>
            <h5>Explore Further</h5>
            <ul>
              <li>
                <strong>Youtube Video:</strong>
                <a
                  href="https://youtu.be/ijDwHkTExJk?si=n2lA_CEbRnDzv92s"
                  target="_blank"
                  >Audio Diffusion Synthesis Showcase</a
                >
              </li>
              <li>
                <strong>Research Paper:</strong>
                <a
                  href="Exploring Audio Diffusion Synthesis (2).pdf"
                  target="_blank"
                  download="Research_Paper"
                  >Audio Diffusion Synthesis Paper</a
                >
              </li>
              <li>
                <strong>Musical Example:</strong>
                <a href="#music" class="my-link" data-bs-dismiss="modal"
                  >Stay With Me</a
                >
              </li>
            </ul>
            <!-- <div class="link-container">
              <a
                href="https://youtu.be/ijDwHkTExJk?si=n2lA_CEbRnDzv92s"
                target="_blank"
                class="fw-bold"
                >Video Presentation</a
              >
            </div>
            <div class="link-container">
              <a href="Your_Link_Here" target="_blank" class="fw-bold"
                >Detailed Paper</a
              >
            </div>
            <a href="#music" class="my-link" data-bs-dismiss="modal"
              >Go to Music Section</a
            > -->

            <!-- <div class="link-container">
              <a href="#music" class=".my-link">Generated Music Samples</a>
            </div> -->
            <!-- <div class="link-container">
              <a href="Your_Link_Here" target="_blank"><i class="bi bi-youtube"></i>Video Presentation</a>
          </div>
          <div class="link-container">
              <a href="Your_Link_Here" target="_blank"><i class="bi bi-file-text"></i>Detailed Paper</a>
          </div>
          <div class="link-container">
              <a href="Your_Link_Here" target="_blank"><i class="bi bi-file-music-fill"></i>Generated Music Samples</a>
          </div> -->
          </div>
          <div class="modal-footer">
            <!-- <button
              type="button"
              class="btn btn-secondary"
              data-bs-dismiss="modal"
            >
              Close
            </button> -->
          </div>
        </div>
      </div>
    </div>
    <!-- Modal for Project 1 -->
    <div
      class="modal fade"
      id="project2Modal"
      tabindex="-1"
      aria-labelledby="project2ModalLabel"
      aria-hidden="true"
    >
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="modal-header">
            <h5 class="modal-title" id="project2ModalLabel">Almost Human</h5>
            <button
              type="button"
              class="btn-close"
              data-bs-dismiss="modal"
              aria-label="Close"
            ></button>
          </div>
          <div class="modal-body">
            <h5>Overview</h5>
            <p>
              "Almost Human," an innovative artistic endeavor initiated at
              Berklee College of Music, delves deep into the intricate interplay
              between Machine Learning and the Artist. This collective is
              propelled by the conviction that the future of music resides at
              the crossroads of cutting-edge technology and human creativity. We
              aspire to democratize the sheer joy of music creation, ensuring
              that this exhilarating experience is open and available to
              everyone.
            </p>
            <!-- Key Contributions & Abstract Here -->
            <strong>Technical Blueprint:</strong>
            <ul>
              <li>
                <strong>Lyrics:</strong> Generated with GPT-4 and a fine tuned
                Llama2 on lyrics, Llama2 generating the name "I'm a Little Too
                Young to Be This Old" and GPT-4 generating lyrics from that
                starting place.
              </li>
              <li>
                <strong>MIDI Generation:</strong> Employed a Transformer XL
                Architecture trained on the Lakh midi dataset.
              </li>
              <li>
                <strong>Vocals:</strong> Generated with
                <a href="http://kits.ai/" target="_blank">Kits.ai</a> vocal
                style transfer models fine-tuned with custom vocal data from
                <a href="https://splice.com/" target="_blank">splice.com</a>. Original vocal performance by Faith Manning.
              </li>
              <li>
                <strong>Sound Design & Sample Generation:</strong> All generated
                with Harmonai’s Dance Diffusion.

                <ul>
                  <li>
                    <strong>Drum Samples:</strong> Leveraged a 20,000 drum
                    sample dataset from my Undergraduate Thesis Project.
                  </li>
                  <li>
                    <strong>Bird Samples:</strong> Recordings from the serene
                    parks of Seattle, Washington.
                  </li>
                  <li>
                    <strong>Instrument Samples:</strong> Multiple models refined
                    on instrument data from <a href="https://splice.com/" target="_blank">splice.com</a>, creating diverse sonic
                    textures.
                  </li>
                  <li>
                    <strong>Glitch Samples:</strong> A collection of 300 unique
                    glitch samples sourced from <a href="https://splice.com/" target="_blank">splice.com</a>, adding a contemporary
                    edge.
                  </li>
                  <li>
                    <strong>Bass Growls:</strong>Utilizing 200 bass growls
                    from <a href="https://splice.com/" target="_blank">splice.com</a>, adding intensity in the drop.
                  </li>
                </ul>
              </li>
            </ul>
            <h5>AI Song Contest Entry</h5>
            <p>
              The piece encapsulates the vision of AI as a bridge in the vast
              landscape of music. It stands as a testament to AI's capability to
              serve beginners, empower those with disabilities, and inspire even
              the most seasoned musicians. This composition is not just a melody
              but a representation of the inclusive and innovative power of AI
              in music.
            </p>
            <h5>Explore Further</h5>
            <li>
              <strong>Musical Example:</strong>
              <a href="#music" class="my-link-2" data-bs-dismiss="modal"
                >I'm A Little Too Young to Be This Old</a
              >
            </li>
            <li>
              <strong>AI Song Competition Page:</strong>
              <a
                href="https://www.aisongcontest.com/participants-2023/almost-human"
                target="_blank"
                >Almost Human</a
              >
            </li>
          </div>
          <div class="modal-footer"></div>
        </div>
      </div>
    </div>
    <div
      class="modal fade"
      id="project3Modal"
      tabindex="-1"
      aria-labelledby="project3ModalLabel"
      aria-hidden="true"
    >
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="modal-header">
            <h5 class="modal-title" id="projec31ModalLabel">
              Catch-A-Waveform Colab Notebook
            </h5>
            <button
              type="button"
              class="btn-close"
              data-bs-dismiss="modal"
              aria-label="Close"
            ></button>
          </div>
          <div class="modal-body">
            <h5>Overview</h5>
            <p>
              "Catch-A-Waveform" is a project primarily focused on audio
              generation and manipulation, with capabilities to generate audio
              from a single short example. This is a full Google Colab build of
              a modified Catch-A-Waveform repository from the Dadabots' Zack
              Zukowski.
            </p>

            <h5>Key Features</h5>
            <ul>
              <li>
                <strong>Google Colaboratory Integration:</strong>
                <ul>
                  <li>
                    Utilize Cloud GPU resources for faster model training.
                  </li>
                </ul>
              </li>
              <li>
                <strong>Google Drive Mounting:</strong>
                <ul>
                  <li>
                    Conveniently access and manage project data stored in Google
                    Drive.
                  </li>
                </ul>
              </li>
              <li>
                <strong>No Code Setup:</strong>
                <ul>
                  <li>
                    Clone the project's GitHub repository effortlessly,
                    requiring minimal coding knowledge.
                  </li>
                </ul>
              </li>
              <li>
                <strong>Model Management:</strong>
                <ul>
                  <li>
                    Model Checkpointing: Easily save and restore model
                    checkpoints, ensuring seamless training progress tracking.
                  </li>
                </ul>
              </li>
              <li>
                <strong>Enhanced Catch-A-Waveform Capabilities:</strong>
                <ul>
                  <li>
                    <strong>Training Run Modes:</strong>
                    <ul>
                      <li>
                        Introduces new training run modes, including resume and
                        transfer, for improved model training flexibility.
                      </li>
                    </ul>
                  </li>
                  <li>
                    <strong>Generating Run Mode:</strong>
                    <ul>
                      <li>
                        Introduces a new generating run mode called "infinite"
                        for generating audio continuously.
                      </li>
                    </ul>
                  </li>
                  <li>
                    <strong>Audio Sampling:</strong>
                    <ul>
                      <li>
                        Implements a new audio sampling method called
                        "--scale_crop" to efficiently fit maximum audio data
                        into memory at different scales.
                      </li>
                    </ul>
                  </li>
                  <li>
                    <strong>Model Building:</strong>
                    <ul>
                      <li>
                        Allows the creation of models with skip connections in
                        the 1D dilated convolution stacks, enhancing model
                        complexity and performance.
                      </li>
                    </ul>
                  </li>
                  <li>
                    <strong>Hyperparameters:</strong>
                    <ul>
                      <li>
                        Adds new hyperparameters tailored for complex music
                        generation, expanding the range from 250Hz to 44.1kHz.
                      </li>
                    </ul>
                  </li>
                  <li>
                    <strong>Conditioning Options:</strong>
                    <ul>
                      <li>
                        Offers options to condition audio generation on any
                        input audio file using "--condition_file" and customize
                        the frequency scale with "--condition_fs."
                      </li>
                    </ul>
                  </li>
                  <li>
                    <strong>Lite Training:</strong>
                    <ul>
                      <li>
                        Includes an experimental "lite training" mode with
                        precision-reduced optimizers to conserve memory
                        resources during training.
                      </li>
                    </ul>
                  </li>
                </ul>
              </li>
            </ul>
            <!-- <ul>
              <li>
                <strong>Swift Setup & Integration:</strong> A streamlined
                auto-repo setup within Google Drive, complemented by effortless
                training from concise data snippets.
              </li>
              <li>
                <strong>High-Quality & Conditional Audio Generation:</strong>
                Pledges vibrant, rich audio outputs, fostering the generation of
                audio under specified conditions.
              </li>
            </ul>

            <h5>Extensions</h5>
            <p>
              Infused with insights from Zack Zukowski, the project integrates
              advanced functionalities such as TTUR, Lite Mode, and Transfer
              Learning, amplifying the quality, versatility, and accessibility
              of the audio generation experience.
            </p> -->

            <h5>Explore Further:</h5>
            <ul>
              <li>
                <strong>Original Project:</strong>
                <a
                  href="https://galgreshler.github.io/Catch-A-Waveform/#"
                  target="_blank"
                  >Catch-A-Waveform</a
                >
              </li>
              <li>
                <strong>Notebook:</strong>
                <a
                  href="https://colab.research.google.com/drive/1bo-SjlCFLZL1mR4XzwAv6nO_R1AXMNR6?usp=drive_link"
                  target="_blank"
                  >Google Colab Notebook</a
                >
              </li>
            </ul>
          </div>
          <div class="modal-footer">
            <!-- <button
              type="button"
              class="btn btn-secondary"
              data-bs-dismiss="modal"
            >
              Close
            </button> -->
          </div>
        </div>
      </div>
    </div>
    <!-- Modal for Project 1 -->
    <div
      class="modal fade"
      id="project4Modal"
      tabindex="-1"
      aria-labelledby="project4ModalLabel"
      aria-hidden="true"
    >
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="modal-header">
            <h5 class="modal-title" id="project4ModalLabel">
              MNIST GUI Deployment
            </h5>
            <button
              type="button"
              class="btn-close"
              data-bs-dismiss="modal"
              aria-label="Close"
            ></button>
          </div>
          <div class="modal-body">
            <div class="card-body">
              <!-- <h4>MNIST GUI Deployment Project</h4> -->
              <h5>Overview</h5>
              <p>
                <!-- Project Description Here -->
                The MNIST Hand-Drawn Digit Recognition project is a Python-based
                application that utilizes Deep Learning to recognize hand-drawn
                digits. The project is structured to train a neural network
                model on the MNIST dataset and subsequently provide a graphical
                user interface (GUI) for real-time digit recognition.
              </p>
              <h5>Key Technology</h5>
              <ul>
                <li>
                  <strong>Python: </strong>the project uses Python as the
                  primary programming language.
                </li>
                <li>
                  <strong>Jupyter Notebooks: </strong>Used for data exploration
                  and model training.
                </li>
                <li>
                  <strong>PyTorch: </strong>Used for model training and
                  inference.
                </li>
                <li>
                  <strong>Tkinter: </strong> Used for GUI application to run
                  model inference.
                </li>
                <li>
                  <strong>Pytest: </strong> Testing ensures for functionality
                  code safety.
                </li>
                <li>
                  <strong>Numpy & Matplotlib: </strong>Used for Data
                  Visualization and Analysis.
                </li>
              </ul>
              <h5>GUI Application</h5>
              <p>
                The GUI application, developed in Python and housed in the
                gui.py file, provides an interactive platform for digit
                recognition using a pre-trained neural network model. Users can
                draw digits on a 280x280 pixel canvas, and upon clicking
                "Predict", the drawn digit is resized, preprocessed, and fed to
                the model, displaying the predicted digit on the interface. The
                application also allows users to clear the canvas and draw new
                digits for prediction. It ensures a user-friendly experience by
                providing clear controls for drawing, predicting, and clearing,
                along with handling potential errors, such as model loading
                issues, gracefully by informing the user through clear error
                messages. This application demonstrates a practical, real-world
                application of a machine learning model in a manner that is
                accessible and interactive for users without technical expertise
                in machine learning.
              </p>

              <h5>Explore Further</h5>
              <ul>
                <li>
                  <strong>GitHub Repository:</strong>
                  <a
                    href="https://github.com/cmsolson75/MNIST_GUI_Project"
                    target="_blank"
                    >MNIST_GUI_Project</a
                  >
                </li>
              </ul>
            </div>
            <div class="modal-footer">
              <!-- <button
                type="button"
                class="btn btn-secondary"
                data-bs-dismiss="modal"
              >
                Close
              </button> -->
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- Modal for Project 1 -->
    <!-- Modal for Project 1 -->
    <div
      class="modal fade"
      id="project5Modal"
      tabindex="-1"
      aria-labelledby="project5ModalLabel"
      aria-hidden="true"
    >
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="modal-header">
            <h5 class="modal-title" id="project5ModalLabel">
              Youtube Playlist Length Calculator
            </h5>
            <button
              type="button"
              class="btn-close"
              data-bs-dismiss="modal"
              aria-label="Close"
            ></button>
          </div>
          <div class="modal-body">
            <h5>Overview</h5>
            <p>
              The YouTube Playlist Length Calculator is a Python script designed
              to calculate the total duration of all videos within a specified
              YouTube playlist. This can be particularly useful for assessing
              the total watch time of course material, tutorial series, or any
              collection of videos grouped into a YouTube playlist.
            </p>
            <h5>Key Points</h5>
            <ul>
              <li>
                <strong>YouTube Data API v3:</strong> The script utilizes the
                YouTube Data API v3 to fetch data about videos and playlists.
              </li>
              <li>
                <strong>Python:</strong> The project is implemented in Python
                and makes use of various libraries and modules.
              </li>
              <li>
                <strong>API Key Management:</strong> The script has
                functionality to manage (save, update, and use) YouTube API
                keys.
              </li>
              <li>
                <strong>Progress Bar:</strong> Utilizes the tqdm library to
                display a progress bar during data retrieval and processing.
              </li>
              <li>
                <strong>Error Handling:</strong> Implements error handling for
                various issues like HTTP errors, connection issues, timeout
                errors, and more.
              </li>
              <li>
                <strong>Command-Line Usage:</strong> The script is designed to
                be used from the command line with various arguments for user
                convenience.
              </li>
            </ul>
            <h5>Explore Further</h5>
            <ul>
              <li>
                <strong>GitHub Repository:</strong>
                <a
                  href="https://github.com/cmsolson75/YouTubePlaylistCalculator"
                  target="_blank"
                  >YouTubePlaylistCalculator</a
                >
              </li>
            </ul>
          </div>
          <div class="modal-footer">
            <!-- <button
              type="button"
              class="btn btn-secondary"
              data-bs-dismiss="modal"
            >
              Close
            </button> -->
          </div>
        </div>
      </div>
    </div>
    <!-- Modal for Project 1 -->
    <div
      class="modal fade"
      id="project6Modal"
      tabindex="-1"
      aria-labelledby="project6ModalLabel"
      aria-hidden="true"
    >
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="modal-header">
            <h5 class="modal-title" id="project6ModalLabel">
              Socket Morse Chat App
            </h5>
            <button
              type="button"
              class="btn-close"
              data-bs-dismiss="modal"
              aria-label="Close"
            ></button>
          </div>
          <div class="modal-body">
            <h5>Overview</h5>
            <p>
              The Socket Morse Chat App is a communication application developed
              in Python that allows users to send and receive messages in Morse
              code through a client-server architecture. The application
              translates text messages into Morse code and plays the
              corresponding audio (dots and dashes) to the users.
            </p>

            <h5>Key Points</h5>
            <ul>
              <li>
                <strong>Client-Server Architecture:</strong> The application
                operates on a client-server model where multiple clients can
                connect to a server and communicate with each other.
              </li>
              <li>
                <strong>Socket Programming:</strong> Utilizes Python's socket
                programming to handle the communication between the server and
                clients.
              </li>
              <li>
                <strong>Multithreading:</strong> Implements threading to manage
                multiple clients and handle sending and receiving messages
                simultaneously.
              </li>
              <li>
                <strong>Morse Code Translation and Playback:</strong> Translates
                text messages into Morse code and plays the corresponding sounds
                using audio files.
              </li>
            </ul>
            <h5>Explore Further</h5>
            <ul>
              <li>
                <strong>Github Repository:</strong>
                <a
                  href="https://github.com/cmsolson75/SocketMorseChatApp"
                  target="_blank"
                  >SocketMorseChatApp</a
                >
              </li>
            </ul>
          </div>
          <div class="modal-footer">
            <!-- <button
              type="button"
              class="btn btn-secondary"
              data-bs-dismiss="modal"
            >
              Close
            </button> -->
          </div>
        </div>
      </div>
    </div>
    <section class="music-section bg-light py-5" id="music">
      <div class="container">
        <h2 class="text-center mb-4">Generative Music</h2>
    
        <!-- Wrap everything in a single container -->
        <div class="music-players-container">
    
          <!-- Song 1 -->
          <article class="music-player mb-3 p-3 border rounded">
            <h5 class="mb-2">
              I'm A Little Too Young to Be This Old | Almost Human | AI Song Competition
            </h5>
            <audio controls class="w-100" id="audio1">
              <source src="music/almost_human_im_a_little_to_young_to_be_this_old.wav" type="audio/mp3" />
              Your browser does not support the audio element.
            </audio>
          </article>
    
          <!-- Song 2 -->
          <article class="music-player mb-3 p-3 border rounded">
            <h5 class="mb-2">
              Stay With Me | Exploring Audio Diffusion Synthesis | Berklee College of Music
            </h5>
            <audio controls class="w-100" id="audio2">
              <source src="music/almost_human_im_a_little_to_young_to_be_this_old.wav" type="audio/mp3" />
              Your browser does not support the audio element.
            </audio>
          </article>
    
          <!-- Song 3 -->
          <article class="music-player mb-3 p-3 border rounded">
            <h5 class="mb-2">
              Desert Dreams | Exploring Audio Diffusion Synthesis | Berklee College of Music
            </h5>
            <audio controls class="w-100" id="audio3">
              <source src="music/almost_human_im_a_little_to_young_to_be_this_old.wav" type="audio/mp3" />
              Your browser does not support the audio element.
            </audio>
          </article>
    
        </div>
      </div>
    </section>
    
    <script>
      // JavaScript to control audio playback
      const audioPlayers = document.querySelectorAll('audio');
    
      audioPlayers.forEach((player) => {
        player.addEventListener('play', () => {
          // Pause all other audio players when one starts playing
          audioPlayers.forEach((otherPlayer) => {
            if (otherPlayer !== player && !otherPlayer.paused) {
              otherPlayer.pause();
            }
          });
        });
      });
    </script>
    
    

    <section class="p-5 bg-light" id="education">
      <!-- Education Section -->
      <div class="container py-5 bg-dark text-white">
        <h2 class="text-center mb-5 fw-bold">Education</h2>

        <div class="row justify-content-center">
          <div class="col-md-6">
            <div class="card bg-secondary text-white">
              <div class="card-body">
                <h3 class="fw-bold">Bachelor's Degree in Music</h3>
                <p><strong>Berklee College of Music</strong></p>
                <ul class="list-unstyled">
                  <li>
                    <strong>Major:</strong> Electronic Production and Design,
                    with a specialization in DSP and AI Music Systems
                  </li>
                  <li><strong>Minor:</strong> Computer Programming</li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>

      <!-- Online Coursework Section -->
      <div class="container py-5 bg-light text-dark">
        <h2 class="text-center mb-5 fw-bold">Online Coursework</h2>
        <div class="row">
          <!-- Single Course Card -->
          <div class="col-md-6 mb-4">
            <div class="card bg-light">
              <div class="card-body">
                <h4 class="card-title fw-bold text-dark">
                  Mathematics for Machine Learning
                </h4>
                <ul class="list-unstyled text-secondary">
                  <li><strong>Platform:</strong> Coursera</li>
                  <li><strong>Completion Date:</strong> 2023</li>
                </ul>
              </div>
            </div>
          </div>
          <div class="col-md-6 mb-4">
            <div class="card bg-light">
              <div class="card-body">
                <h4 class="card-title fw-bold text-dark">
                  Deep Learning Specialization
                </h4>
                <ul class="list-unstyled text-secondary">
                  <li><strong>Platform:</strong> Coursera</li>
                  <li><strong>Completion Date:</strong> 2022</li>
                </ul>
              </div>
            </div>
          </div>
          <div class="col-md-6 mb-4">
            <div class="card bg-light">
              <div class="card-body">
                <h4 class="card-title fw-bold text-dark">
                  Complete TensorFlow 2 and Keras Bootcamp
                </h4>
                <ul class="list-unstyled text-secondary">
                  <li><strong>Platform:</strong> Udemy</li>
                  <li><strong>Completion Date:</strong> 2021</li>
                </ul>
              </div>
            </div>
          </div>
          <div class="col-md-6 mb-4">
            <div class="card bg-light">
              <div class="card-body">
                <h4 class="card-title fw-bold text-dark">
                  The Complete Python Bootcamp: From Zero to Hero
                </h4>
                <ul class="list-unstyled text-secondary">
                  <li><strong>Platform:</strong> Udemy</li>
                  <li><strong>Completion Date:</strong> 2020</li>
                </ul>
              </div>
            </div>
          </div>
          <!-- Additional Course Cards... -->
          <!-- ... -->
        </div>
      </div>
    </section>

    <footer class="p-5 text-white bg-dark" id="contact">
      <h2>Contact</h2>
      <a href="Your_LinkedIn_Profile" class="text-white m-2"
        ><i class="fab fa-linkedin"></i
      ></a>
      <a href="mailto:Your_Email_Address" class="text-white m-2"
        ><i class="fas fa-envelope"></i
      ></a>
      <p>
        Thank you for visiting my portfolio. Feel free to connect with me on
        LinkedIn or send me an email.
      </p>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.10.2/dist/umd/popper.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.min.js"></script>
  </body>
</html>
